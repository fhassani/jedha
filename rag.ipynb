{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings, Settings\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "import ollama\n",
    "from ollama import chat\n",
    "from ollama import embeddings\n",
    "from ollama import EmbeddingsResponse\n",
    "from ollama import ChatResponse\n",
    "\n",
    "from ddg import Duckduckgo\n",
    "\n",
    "def extract_pages_from_pdf(file_path):\n",
    "    pdf_reader = PdfReader(file_path)\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "\n",
    "    page_offset = 0\n",
    "    text = \"\"\n",
    "\n",
    "    pages = []\n",
    "    for page_num in range(page_offset, num_pages):\n",
    "        pages.append(pdf_reader.pages[page_num].extract_text())\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"RAW_recipes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = []\n",
    "for index, row in df.iterrows():\n",
    "    nutrition = eval(row[\"nutrition\"])\n",
    "    nutrition_facts = f\"Nutritional facts:\\n#Calories: {nutrition[0]}\\n Total fat: {nutrition[1]}\\n Sugar: {nutrition[2]}\\n Sodium: {nutrition[3]}\\n Protein: {nutrition[4]}\\n Saturated fat: {nutrition[5]}\"\n",
    "    name = f\"Name: {row['name']}\"\n",
    "    description = f\"Description:\\n {row['description']}\"\n",
    "    ingredients = \"Ingredients:\\n\" + \"\\n\".join(eval(row[\"ingredients\"]))\n",
    "    steps = \"Steps:\\n\" + \"\\n\".join(eval(row[\"steps\"]))\n",
    "    \n",
    "    text =  f\"{name} \\n{description} \\n{nutrition_facts} \\n{ingredients} \\n{steps}\"\n",
    "    recipes.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "#local_embedding_model = \"nomic-embed-text\"\n",
    "local_embedding_model = \"bge-m3\"\n",
    "\n",
    "gemini_model = genai.GenerativeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chroma_db_without_embedding_function(name):\n",
    "    chroma_client = chromadb.PersistentClient(path=\"database/\")\n",
    "    return chroma_client.get_or_create_collection(name=name)\n",
    "\n",
    "def delete_chroma_db(name):\n",
    "    chroma_client = chromadb.PersistentClient(path=\"database/\")\n",
    "    chroma_client.delete_collection(name=name)\n",
    "\n",
    "def add_docs_to_db(docs, ids, embeds, db):\n",
    "    num_of_docs = len(docs)\n",
    "    j=0\n",
    "    while num_of_docs > 0:\n",
    "        num = min(num_of_docs, 5000)\n",
    "        db.add(\n",
    "            documents = docs[j*5000:(j*5000)+num],\n",
    "            ids = ids[j*5000:(j*5000)+num],\n",
    "            embeddings=embeds[j*5000:(j*5000)+num])\n",
    "        j += 1\n",
    "        num_of_docs -= num\n",
    "\n",
    "def generate_blocs_db_items(initial_size, documents, embedding_model):\n",
    "    docs = []\n",
    "    ids = []\n",
    "    embeds = []\n",
    "\n",
    "    index = initial_size\n",
    "    for i, d in tqdm(enumerate(documents), total=len(documents), desc=\"Creating DB items\"):\n",
    "        docs.append(d)\n",
    "        ids.append(str(index))\n",
    "        embeds.append(embeddings(\n",
    "            model = embedding_model, \n",
    "            prompt=d).embedding)\n",
    "        index += 1\n",
    "    return docs, ids, embeds, index\n",
    "\n",
    "def create_chroma_db(documents, embedding_model, db_name):\n",
    "    \n",
    "    chroma_client = chromadb.PersistentClient(path=\"database/\")\n",
    "\n",
    "    db = chroma_client.get_or_create_collection(name=db_name)\n",
    "\n",
    "    initial_size = db.count()\n",
    "\n",
    "    index = initial_size\n",
    "\n",
    "    docs, ids, embeds, index = generate_blocs_db_items(index, documents, embedding_model)\n",
    "    add_docs_to_db(docs, ids, embeds, db)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_chroma_db(\"recipes\")\n",
    "create_chroma_db(recipes[:1000], local_embedding_model, \"recipes\")\n",
    "chroma_db = get_chroma_db_without_embedding_function(\"recipes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passages_with_embeddings_and_articles(query, chat_model, embedding_model, db):\n",
    "\n",
    "    embeddings_response = embeddings(\n",
    "        model=embedding_model,\n",
    "        prompt=query) \n",
    "    \n",
    "    n_results = 10\n",
    "\n",
    "    results = db.query(\n",
    "        query_embeddings=embeddings_response.embedding,  \n",
    "        n_results= n_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def convert_passages_to_list_updown(passages):\n",
    "    context = \"\"\n",
    "\n",
    "    a = passages[\"documents\"][0]\n",
    "    b = passages[\"ids\"][0]\n",
    "\n",
    "    b = list(map(str, b))\n",
    "    x = [val for _, val in sorted(zip(b, a))]\n",
    "    \n",
    "    for passage in x:\n",
    "        context += passage + \"\\n\"\n",
    "    return context\n",
    "\n",
    "def make_prompt_legal(query, passage):\n",
    "\n",
    "    query_oneline = query.replace(\"\\n\", \"\\n\")\n",
    "\n",
    "    passage_oneline = passage.replace(\"\\n\", \"\\n\")\n",
    "\n",
    "    #print(passage_oneline)\n",
    "\n",
    "    # This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "    prompt = f\"\"\"You are a chatbot specialized in answering queries from users about recipes based on the CONTEXT bellow.\n",
    "        Your answer must be detailed and nicely formatted.\n",
    "        In your answer, highlight the ingredients contained in the user query. \n",
    "    \n",
    "    QUERY: \n",
    "    {query_oneline}\n",
    "    \n",
    "    CONTEXT: \n",
    "    {passage_oneline}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def answer_question_with_gemini(query, embedding_db, chat_model, embedding_model):\n",
    "\n",
    "    passages = get_relevant_passages_with_embeddings_and_articles(query, chat_model, embedding_model, embedding_db)\n",
    "\n",
    "    context = convert_passages_to_list_updown(passages)\n",
    "\n",
    "    prompt = make_prompt_legal(query, context)\n",
    "\n",
    "    answer = chat_model.generate_content(prompt)\n",
    "\n",
    "    return answer.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query= \"give me a recipe with bananas, eggs, lemon, orange and flour\"\n",
    "Markdown(answer_question_with_gemini(query, chroma_db, gemini_model, local_embedding_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddg_api = Duckduckgo()\n",
    "#results = ddg_api.search(f\"find youtube videos for a recipe similar to this one {recipes[2]}\")\n",
    "results = ddg_api.search(f\"find youtube videos corresponding to this query: {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results['data']:\n",
    "    if (\"https://www.youtube.com\" in result['url']):\n",
    "        print(result['url'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
